{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Star Galaxy classification using the Sklearn custom script in SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "#this boto3 library is use to connect S3 bucket:\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stargalaxybucketsagemaker\n",
    "sm_boto3 = boto3.client(\"sagemaker\", region_name='us-east-1')\n",
    "sess = sagemaker.Session(boto3.session.Session(region_name='us-east-1'))\n",
    "region = sess.boto_session.region_name\n",
    "bucket = 'name_of_bucket'# mention created S3 bucket name \n",
    "print('using S3 bucket '+ bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('star_classification.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(columns=[\"obj_ID\",\"run_ID\",\"rerun_ID\",\"cam_col\",\"field_ID\",\"spec_obj_ID\",\"plate\",\"MJD\",\"fiber_ID\"])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df1['class']\n",
    "df1 = df1.drop(columns=['class'])\n",
    "features = list(df1.columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1[features]\n",
    "y = label\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = pd.DataFrame(X_train)\n",
    "trainX['label'] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test)\n",
    "testX['label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv(\"train-v-1.csv\", index = False)\n",
    "testX.to_csv(\"test-v-1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#send data to S3. SageMaker will take training data from S3.\n",
    "sk_prefix = \"sagemaker/star_galaxy_classification/sklearncontainer\"\n",
    "trainpath = sess.upload_data(\n",
    "    path = \"train-v-1.csv\", bucket = bucket, key_prefix = sk_prefix\n",
    ")\n",
    "testpath = sess.upload_data(\n",
    "    path = \"test-v-1.csv\", bucket = bucket, key_prefix = sk_prefix\n",
    ")\n",
    "print(trainpath)\n",
    "print(testpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile script.py \n",
    "\n",
    "import sklearn \n",
    "import joblib\n",
    "import boto3\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "if __name__ == \"main\":\n",
    "    print(\"Extracting arguments... \")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    #hyperparameter sent by the client are passed as command line arguments to the script.\n",
    "    parser.add_argument(\"--n_estimator\", type=int, default= 100)\n",
    "    parser.add_argument(\"--random_state\", type=int, default = 0)\n",
    "\n",
    "    #data, model, output directories\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train-v-1.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test-v-1.csv\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"SKLearn version:\", sklearn.__version__)\n",
    "    print(\"joblib version:\", joblib.__version__)\n",
    "\n",
    "    print(\"[INFO] Reading data\")\n",
    "    print()\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    features = list(train_df.columns)\n",
    "    label = features.pop(-1)\n",
    "    print(\"Building training and testing datasets\")\n",
    "    print()\n",
    "    X_train = train_df[features]\n",
    "    X_test = test_df[features]\n",
    "    y_train = train_df[label]\n",
    "    y_test = test_df[label]\n",
    "\n",
    "    print(\"column oreder:\")\n",
    "    print(features)\n",
    "    print()\n",
    "\n",
    "    print(\"label column is:\", label)\n",
    "    print()\n",
    "\n",
    "    print(\"data shape\")\n",
    "    print()\n",
    "    print(\"-----shape of traning data(80%)-----\") \n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(\"-----shape of testing data(20%)-----\")\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    print()\n",
    "\n",
    "    print(\"Training Random Forest Model......\")\n",
    "    print()\n",
    "    model = RandomForestClassifier(n_estimators = args.n_estimators, random_state=args.random_state, verbose = args.verbose)\n",
    "    model.fit(X_train, y_train)\n",
    "    print()\n",
    "\n",
    "    model_path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, model_path)\n",
    "    print(\"model persisted at \" + model_path)\n",
    "    print()\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    test_rep = classification_report(y_test, y_pred_test)\n",
    "\n",
    "    print()\n",
    "    print(\"---- metrics results for testing data ----\")\n",
    "    print()\n",
    "    print(\"total rows are: \", X_test.shape[0])  \n",
    "    print('[testing] model accuracy is: ', test_acc)\n",
    "    print('[testing] testing report: ')\n",
    "    print(test_rep)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"script.py\",\n",
    "    #role = \"arn:aws:iam::336195629133:role/service-role/AmazonSageMaker-ExecutionRole-20230825T003814\",\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.m5.large\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name = \"RF-custom-sklearn\",\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": 100,\n",
    "        \"random_state\": 0,\n",
    "    },\n",
    "    use_spot_instances = True,\n",
    "    max_wait = 7200,\n",
    "    max_run = 3600\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launch training job with asynchronous call\n",
    "sklearn_estimator.fit({\"train\":trainpath, \"test\":testpath}, wait = True)\n",
    "#sklearn_estimator.fit({\"train\":datapath}, wait=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs = \"None\")\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName = sklearn_estimator.latest_training_job.name \n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"model artifact persisted at \" +  artifact)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# model_name = \"Custom-sklearn-model-\"+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "# new_model = SKLearnModel(       \n",
    "#     name = model_name,\n",
    "#     model_data = artifact,\n",
    "#     role = \"arn:aws:iam::336195629133:role/service-role/AmazonSageMaker-ExecutionRole-20230825T003814\",\n",
    "#     entry_point=\"script.py\",\n",
    "#     framework_version=FRAMEWORK_VERSION\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"Custom-sklearn-model-\"+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Endpoint_name = {}\".format(endpoint_name))\n",
    "\n",
    "predictor = new_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.Xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
